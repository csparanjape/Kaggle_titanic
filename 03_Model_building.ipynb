{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b992e4",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "This notebook trains and examins different ML classifiers on training data dataset. \n",
    "\n",
    "* K Nearest neighbours\n",
    "* SVM\n",
    "* Random forest\n",
    "* Logistic regression\n",
    "* Decision Tree\n",
    "* ADABoost\n",
    "* ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c3d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf0a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('./data/train_features_processed.csv')\n",
    "y_tr = pd.read_csv('./data/train_labels_processed.csv')\n",
    "y_tr = y_tr.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47ac51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Age      891 non-null    float64\n",
      " 1   SibSp    891 non-null    float64\n",
      " 2   Parch    891 non-null    float64\n",
      " 3   Fare     891 non-null    float64\n",
      " 4   female   891 non-null    float64\n",
      " 5   C        891 non-null    float64\n",
      " 6   Q        891 non-null    float64\n",
      " 7   Class_2  891 non-null    float64\n",
      " 8   Class_3  891 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 62.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a27691",
   "metadata": {},
   "source": [
    "## 1. Splitting training data\n",
    " Split training dataset into training dataset, cross validation dataset and test dataset - 55%,25% and 20% resp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d538332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(df_tr,\n",
    "                                                              y_tr,\n",
    "                                                              test_size=0.2,\n",
    "                                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train_temp,\n",
    "                                                y_train_temp,\n",
    "                                                test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c5cd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51383b6c",
   "metadata": {},
   "source": [
    "## 2. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e9842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestModel(model, X_train, X_cv, y_train, y_cv, grid):\n",
    "    model_cv = GridSearchCV(model, grid, cv=4)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", model_cv.best_params_)\n",
    "    print(\"accuracy :\", model_cv.best_score_)\n",
    "    mod_best= model_cv.best_estimator_\n",
    "    return mod_best\n",
    "\n",
    "\n",
    "def testModel(model, X_train, X_cv, y_train, y_cv):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    y_pred_cv = model.predict(X_cv)\n",
    "    precision_tr, recall_tr, fscore_tr, support_tr = precision_recall_fscore_support(\n",
    "        y_train, y_pred_tr, average='macro')\n",
    "    precision_cv, recall_cv, fscore_cv, support_cv = precision_recall_fscore_support(\n",
    "        y_cv, y_pred_cv, average='macro')\n",
    "    report= np.array([precision_tr, recall_tr, fscore_tr, precision_cv, recall_cv, fscore_cv])\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0b4ea",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b962ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.17012542798525856, 'solver': 'newton-cg'}\n",
      "accuracy : 0.8016215912916619\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(class_weight='auto', max_iter=200)\n",
    "grid = {\n",
    "    'C': np.logspace(-5, 0, 40),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "logReg_best=bestModel(logReg, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5663670",
   "metadata": {},
   "source": [
    "### 2. K-Nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3fe5e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "accuracy : 0.8034171249018068\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "grid = {\n",
    "    'n_neighbors': np.int0(np.linspace(3, 22, 20)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "knn_best=bestModel(knn, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1392e2",
   "metadata": {},
   "source": [
    "### 3. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ffdba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'splitter': 'best'}\n",
      "accuracy : 0.7602822354393447\n"
     ]
    }
   ],
   "source": [
    "decTree = DecisionTreeClassifier()\n",
    "grid = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random']}\n",
    "decTree_best=bestModel(decTree, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f041a",
   "metadata": {},
   "source": [
    "### 4. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f01b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'n_estimators': 10}\n",
      "accuracy : 0.807106385366401\n"
     ]
    }
   ],
   "source": [
    "rnFr = RandomForestClassifier()\n",
    "grid = {\n",
    "    'n_estimators': np.array([10,20,30]),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "rnFr_best=bestModel(rnFr, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f907c4",
   "metadata": {},
   "source": [
    "### 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c53698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.0774263682681127, 'kernel': 'poly'}\n",
      "accuracy : 0.8090421950398383\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "grid = {\n",
    "    'C': np.logspace(-5, 2, 10),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "svm_best=bestModel(svm, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2780b4f",
   "metadata": {},
   "source": [
    "### 6. ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14778ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'algorithm': 'SAMME'}\n",
      "accuracy : 0.7940747390865223\n"
     ]
    }
   ],
   "source": [
    "adab = AdaBoostClassifier()\n",
    "grid = {'algorithm': ['SAMME', 'SAMME.R']}\n",
    "adab_best=bestModel(adab, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de113e6",
   "metadata": {},
   "source": [
    "### 7. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af652589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:22] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "tuned hpyerparameters :(best parameters)  {'n_estimators': 70}\n",
      "accuracy : 0.7827404331724834\n"
     ]
    }
   ],
   "source": [
    "xgbst = xgb.XGBClassifier(use_label_encoder=False, objective='binary:logistic')\n",
    "grid = {'n_estimators': np.array([50, 70, 100])}\n",
    "xgbst_best=bestModel(xgbst, X_train, X_cv, y_train, y_cv, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed6cda",
   "metadata": {},
   "source": [
    "### 8. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521881f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e5aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mod=Sequential()\n",
    "ann_mod.add(Dense(units=9,activation='relu'))\n",
    "ann_mod.add(Dropout(0.5))\n",
    "ann_mod.add(Dense(units=18,activation='relu'))\n",
    "ann_mod.add(Dropout(0.5))\n",
    "ann_mod.add(Dense(units=1,activation='sigmoid'))\n",
    "ann_mod.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2d1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9a22c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "17/17 [==============================] - 1s 39ms/step - loss: 0.7100 - val_loss: 0.6929\n",
      "Epoch 2/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.6946 - val_loss: 0.6742\n",
      "Epoch 3/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.6620 - val_loss: 0.6591\n",
      "Epoch 4/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6664 - val_loss: 0.6453\n",
      "Epoch 5/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6589 - val_loss: 0.6314\n",
      "Epoch 6/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.6538 - val_loss: 0.6177\n",
      "Epoch 7/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6300 - val_loss: 0.6045\n",
      "Epoch 8/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.6203 - val_loss: 0.5901\n",
      "Epoch 9/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6215 - val_loss: 0.5781\n",
      "Epoch 10/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.6258 - val_loss: 0.5677\n",
      "Epoch 11/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.6128 - val_loss: 0.5562\n",
      "Epoch 12/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.6085 - val_loss: 0.5471\n",
      "Epoch 13/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.5892 - val_loss: 0.5385\n",
      "Epoch 14/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5762 - val_loss: 0.5303\n",
      "Epoch 15/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5667 - val_loss: 0.5213\n",
      "Epoch 16/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5748 - val_loss: 0.5140\n",
      "Epoch 17/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5706 - val_loss: 0.5105\n",
      "Epoch 18/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5879 - val_loss: 0.5055\n",
      "Epoch 19/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5294 - val_loss: 0.4994\n",
      "Epoch 20/600\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.5693 - val_loss: 0.4941\n",
      "Epoch 21/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.5567 - val_loss: 0.4917\n",
      "Epoch 22/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5276 - val_loss: 0.4878\n",
      "Epoch 23/600\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.5254 - val_loss: 0.4852\n",
      "Epoch 24/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5280 - val_loss: 0.4833\n",
      "Epoch 25/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.5690 - val_loss: 0.4813\n",
      "Epoch 26/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4753 - val_loss: 0.4774\n",
      "Epoch 27/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.5187 - val_loss: 0.4752\n",
      "Epoch 28/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5248 - val_loss: 0.4739\n",
      "Epoch 29/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4884 - val_loss: 0.4725\n",
      "Epoch 30/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5127 - val_loss: 0.4711\n",
      "Epoch 31/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5420 - val_loss: 0.4694\n",
      "Epoch 32/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5009 - val_loss: 0.4673\n",
      "Epoch 33/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5315 - val_loss: 0.4646\n",
      "Epoch 34/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5032 - val_loss: 0.4622\n",
      "Epoch 35/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4542 - val_loss: 0.4609\n",
      "Epoch 36/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5022 - val_loss: 0.4597\n",
      "Epoch 37/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5375 - val_loss: 0.4602\n",
      "Epoch 38/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5084 - val_loss: 0.4619\n",
      "Epoch 39/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4932 - val_loss: 0.4608\n",
      "Epoch 40/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5184 - val_loss: 0.4590\n",
      "Epoch 41/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4899 - val_loss: 0.4569\n",
      "Epoch 42/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.5420 - val_loss: 0.4568\n",
      "Epoch 43/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5125 - val_loss: 0.4566\n",
      "Epoch 44/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5151 - val_loss: 0.4564\n",
      "Epoch 45/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5211 - val_loss: 0.4567\n",
      "Epoch 46/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5154 - val_loss: 0.4555\n",
      "Epoch 47/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5038 - val_loss: 0.4558\n",
      "Epoch 48/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4792 - val_loss: 0.4540\n",
      "Epoch 49/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5235 - val_loss: 0.4533\n",
      "Epoch 50/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4948 - val_loss: 0.4526\n",
      "Epoch 51/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4684 - val_loss: 0.4512\n",
      "Epoch 52/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5655 - val_loss: 0.4518\n",
      "Epoch 53/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5311 - val_loss: 0.4526\n",
      "Epoch 54/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5301 - val_loss: 0.4521\n",
      "Epoch 55/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4822 - val_loss: 0.4527\n",
      "Epoch 56/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5066 - val_loss: 0.4524\n",
      "Epoch 57/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4874 - val_loss: 0.4524\n",
      "Epoch 58/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5339 - val_loss: 0.4528\n",
      "Epoch 59/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4992 - val_loss: 0.4526\n",
      "Epoch 60/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5187 - val_loss: 0.4529\n",
      "Epoch 61/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5178 - val_loss: 0.4523\n",
      "Epoch 62/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5198 - val_loss: 0.4520\n",
      "Epoch 63/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5116 - val_loss: 0.4511\n",
      "Epoch 64/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4879 - val_loss: 0.4500\n",
      "Epoch 65/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5189 - val_loss: 0.4489\n",
      "Epoch 66/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5254 - val_loss: 0.4485\n",
      "Epoch 67/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4838 - val_loss: 0.4486\n",
      "Epoch 68/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4682 - val_loss: 0.4479\n",
      "Epoch 69/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5097 - val_loss: 0.4488\n",
      "Epoch 70/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4956 - val_loss: 0.4496\n",
      "Epoch 71/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4839 - val_loss: 0.4489\n",
      "Epoch 72/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5095 - val_loss: 0.4479\n",
      "Epoch 73/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4631 - val_loss: 0.4465\n",
      "Epoch 74/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4825 - val_loss: 0.4452\n",
      "Epoch 75/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5157 - val_loss: 0.4452\n",
      "Epoch 76/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4762 - val_loss: 0.4453\n",
      "Epoch 77/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4847 - val_loss: 0.4446\n",
      "Epoch 78/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4783 - val_loss: 0.4445\n",
      "Epoch 79/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4797 - val_loss: 0.4427\n",
      "Epoch 80/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4852 - val_loss: 0.4433\n",
      "Epoch 81/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4969 - val_loss: 0.4441\n",
      "Epoch 82/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4829 - val_loss: 0.4433\n",
      "Epoch 83/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5075 - val_loss: 0.4431\n",
      "Epoch 84/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4901 - val_loss: 0.4429\n",
      "Epoch 85/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4822 - val_loss: 0.4426\n",
      "Epoch 86/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4268 - val_loss: 0.4405\n",
      "Epoch 87/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5035 - val_loss: 0.4410\n",
      "Epoch 88/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5090 - val_loss: 0.4411\n",
      "Epoch 89/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5094 - val_loss: 0.4419\n",
      "Epoch 90/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4706 - val_loss: 0.4420\n",
      "Epoch 91/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5107 - val_loss: 0.4420\n",
      "Epoch 92/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4689 - val_loss: 0.4421\n",
      "Epoch 93/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4973 - val_loss: 0.4423\n",
      "Epoch 94/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4840 - val_loss: 0.4416\n",
      "Epoch 95/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5017 - val_loss: 0.4420\n",
      "Epoch 96/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4507 - val_loss: 0.4415\n",
      "Epoch 97/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5321 - val_loss: 0.4421\n",
      "Epoch 98/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4982 - val_loss: 0.4405\n",
      "Epoch 99/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4720 - val_loss: 0.4406\n",
      "Epoch 100/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5037 - val_loss: 0.4406\n",
      "Epoch 101/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5185 - val_loss: 0.4411\n",
      "Epoch 102/600\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.4723 - val_loss: 0.4408\n",
      "Epoch 103/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5187 - val_loss: 0.4411\n",
      "Epoch 104/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4930 - val_loss: 0.4412\n",
      "Epoch 105/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.5201 - val_loss: 0.4413\n",
      "Epoch 106/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4821 - val_loss: 0.4409\n",
      "Epoch 107/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5213 - val_loss: 0.4419\n",
      "Epoch 108/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4828 - val_loss: 0.4415\n",
      "Epoch 109/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4867 - val_loss: 0.4405\n",
      "Epoch 110/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4894 - val_loss: 0.4406\n",
      "Epoch 111/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4635 - val_loss: 0.4396\n",
      "Epoch 112/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4735 - val_loss: 0.4391\n",
      "Epoch 113/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4809 - val_loss: 0.4397\n",
      "Epoch 114/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5163 - val_loss: 0.4394\n",
      "Epoch 115/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4975 - val_loss: 0.4383\n",
      "Epoch 116/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4967 - val_loss: 0.4370\n",
      "Epoch 117/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4677 - val_loss: 0.4371\n",
      "Epoch 118/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4818 - val_loss: 0.4386\n",
      "Epoch 119/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4662 - val_loss: 0.4382\n",
      "Epoch 120/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4713 - val_loss: 0.4376\n",
      "Epoch 121/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4806 - val_loss: 0.4368\n",
      "Epoch 122/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4853 - val_loss: 0.4368\n",
      "Epoch 123/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4678 - val_loss: 0.4364\n",
      "Epoch 124/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4802 - val_loss: 0.4360\n",
      "Epoch 125/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5065 - val_loss: 0.4358\n",
      "Epoch 126/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4854 - val_loss: 0.4352\n",
      "Epoch 127/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4573 - val_loss: 0.4352\n",
      "Epoch 128/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4828 - val_loss: 0.4347\n",
      "Epoch 129/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5057 - val_loss: 0.4343\n",
      "Epoch 130/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4793 - val_loss: 0.4349\n",
      "Epoch 131/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4651 - val_loss: 0.4342\n",
      "Epoch 132/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4534 - val_loss: 0.4335\n",
      "Epoch 133/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4930 - val_loss: 0.4334\n",
      "Epoch 134/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4817 - val_loss: 0.4333\n",
      "Epoch 135/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4636 - val_loss: 0.4329\n",
      "Epoch 136/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4549 - val_loss: 0.4340\n",
      "Epoch 137/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4842 - val_loss: 0.4344\n",
      "Epoch 138/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4699 - val_loss: 0.4346\n",
      "Epoch 139/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5212 - val_loss: 0.4353\n",
      "Epoch 140/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4762 - val_loss: 0.4351\n",
      "Epoch 141/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.5011 - val_loss: 0.4351\n",
      "Epoch 142/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5109 - val_loss: 0.4349\n",
      "Epoch 143/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4844 - val_loss: 0.4348\n",
      "Epoch 144/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5109 - val_loss: 0.4356\n",
      "Epoch 145/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.5046 - val_loss: 0.4360\n",
      "Epoch 146/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4752 - val_loss: 0.4352\n",
      "Epoch 147/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4678 - val_loss: 0.4349\n",
      "Epoch 148/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4504 - val_loss: 0.4345\n",
      "Epoch 149/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4667 - val_loss: 0.4339\n",
      "Epoch 150/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4426 - val_loss: 0.4335\n",
      "Epoch 151/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5013 - val_loss: 0.4342\n",
      "Epoch 152/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4541 - val_loss: 0.4343\n",
      "Epoch 153/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4580 - val_loss: 0.4327\n",
      "Epoch 154/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4666 - val_loss: 0.4318\n",
      "Epoch 155/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4621 - val_loss: 0.4326\n",
      "Epoch 156/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4929 - val_loss: 0.4334\n",
      "Epoch 157/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4793 - val_loss: 0.4330\n",
      "Epoch 158/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4770 - val_loss: 0.4329\n",
      "Epoch 159/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5090 - val_loss: 0.4323\n",
      "Epoch 160/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4511 - val_loss: 0.4315\n",
      "Epoch 161/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4490 - val_loss: 0.4310\n",
      "Epoch 162/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4619 - val_loss: 0.4319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4767 - val_loss: 0.4320\n",
      "Epoch 164/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4793 - val_loss: 0.4323\n",
      "Epoch 165/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4676 - val_loss: 0.4314\n",
      "Epoch 166/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5014 - val_loss: 0.4309\n",
      "Epoch 167/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4292 - val_loss: 0.4305\n",
      "Epoch 168/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5035 - val_loss: 0.4317\n",
      "Epoch 169/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4568 - val_loss: 0.4308\n",
      "Epoch 170/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4334 - val_loss: 0.4296\n",
      "Epoch 171/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5157 - val_loss: 0.4297\n",
      "Epoch 172/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4400 - val_loss: 0.4284\n",
      "Epoch 173/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5557 - val_loss: 0.4279\n",
      "Epoch 174/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4944 - val_loss: 0.4279\n",
      "Epoch 175/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4908 - val_loss: 0.4285\n",
      "Epoch 176/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5114 - val_loss: 0.4300\n",
      "Epoch 177/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4553 - val_loss: 0.4283\n",
      "Epoch 178/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5013 - val_loss: 0.4280\n",
      "Epoch 179/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4868 - val_loss: 0.4278\n",
      "Epoch 180/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4558 - val_loss: 0.4285\n",
      "Epoch 181/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4820 - val_loss: 0.4288\n",
      "Epoch 182/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4464 - val_loss: 0.4282\n",
      "Epoch 183/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4488 - val_loss: 0.4276\n",
      "Epoch 184/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4922 - val_loss: 0.4275\n",
      "Epoch 185/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4699 - val_loss: 0.4259\n",
      "Epoch 186/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5066 - val_loss: 0.4255\n",
      "Epoch 187/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4579 - val_loss: 0.4248\n",
      "Epoch 188/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4611 - val_loss: 0.4265\n",
      "Epoch 189/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4723 - val_loss: 0.4266\n",
      "Epoch 190/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4833 - val_loss: 0.4259\n",
      "Epoch 191/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4744 - val_loss: 0.4245\n",
      "Epoch 192/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4327 - val_loss: 0.4235\n",
      "Epoch 193/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4784 - val_loss: 0.4238\n",
      "Epoch 194/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5425 - val_loss: 0.4252\n",
      "Epoch 195/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4991 - val_loss: 0.4253\n",
      "Epoch 196/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4898 - val_loss: 0.4259\n",
      "Epoch 197/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4444 - val_loss: 0.4257\n",
      "Epoch 198/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4614 - val_loss: 0.4257\n",
      "Epoch 199/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4743 - val_loss: 0.4260\n",
      "Epoch 200/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4559 - val_loss: 0.4251\n",
      "Epoch 201/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4942 - val_loss: 0.4252\n",
      "Epoch 202/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4509 - val_loss: 0.4253\n",
      "Epoch 203/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 204/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4875 - val_loss: 0.4243\n",
      "Epoch 205/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4933 - val_loss: 0.4242\n",
      "Epoch 206/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4566 - val_loss: 0.4237\n",
      "Epoch 207/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4678 - val_loss: 0.4239\n",
      "Epoch 208/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4888 - val_loss: 0.4245\n",
      "Epoch 209/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5065 - val_loss: 0.4244\n",
      "Epoch 210/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4765 - val_loss: 0.4243\n",
      "Epoch 211/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5214 - val_loss: 0.4248\n",
      "Epoch 212/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4763 - val_loss: 0.4254\n",
      "Epoch 213/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.5064 - val_loss: 0.4253\n",
      "Epoch 214/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4924 - val_loss: 0.4250\n",
      "Epoch 215/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4880 - val_loss: 0.4242\n",
      "Epoch 216/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4611 - val_loss: 0.4239\n",
      "Epoch 217/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4573 - val_loss: 0.4229\n",
      "Epoch 218/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4523 - val_loss: 0.4235\n",
      "Epoch 219/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4453 - val_loss: 0.4241\n",
      "Epoch 220/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4694 - val_loss: 0.4237\n",
      "Epoch 221/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4561 - val_loss: 0.4236\n",
      "Epoch 222/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4572 - val_loss: 0.4223\n",
      "Epoch 223/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4721 - val_loss: 0.4220\n",
      "Epoch 224/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4537 - val_loss: 0.4218\n",
      "Epoch 225/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4802 - val_loss: 0.4222\n",
      "Epoch 226/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4379 - val_loss: 0.4223\n",
      "Epoch 227/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5028 - val_loss: 0.4223\n",
      "Epoch 228/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5063 - val_loss: 0.4226\n",
      "Epoch 229/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4382 - val_loss: 0.4229\n",
      "Epoch 230/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4508 - val_loss: 0.4229\n",
      "Epoch 231/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4769 - val_loss: 0.4238\n",
      "Epoch 232/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5094 - val_loss: 0.4236\n",
      "Epoch 233/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4213 - val_loss: 0.4225\n",
      "Epoch 234/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4624 - val_loss: 0.4218\n",
      "Epoch 235/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4233 - val_loss: 0.4213\n",
      "Epoch 236/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4829 - val_loss: 0.4214\n",
      "Epoch 237/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4311 - val_loss: 0.4204\n",
      "Epoch 238/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4612 - val_loss: 0.4200\n",
      "Epoch 239/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4873 - val_loss: 0.4198\n",
      "Epoch 240/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4889 - val_loss: 0.4194\n",
      "Epoch 241/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4506 - val_loss: 0.4193\n",
      "Epoch 242/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4754 - val_loss: 0.4201\n",
      "Epoch 243/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4208 - val_loss: 0.4203\n",
      "Epoch 244/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4874 - val_loss: 0.4199\n",
      "Epoch 245/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4593 - val_loss: 0.4196\n",
      "Epoch 246/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4342 - val_loss: 0.4187\n",
      "Epoch 247/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4631 - val_loss: 0.4191\n",
      "Epoch 248/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4310 - val_loss: 0.4193\n",
      "Epoch 249/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4570 - val_loss: 0.4188\n",
      "Epoch 250/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4792 - val_loss: 0.4193\n",
      "Epoch 251/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5068 - val_loss: 0.4194\n",
      "Epoch 252/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4488 - val_loss: 0.4191\n",
      "Epoch 253/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4794 - val_loss: 0.4195\n",
      "Epoch 254/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4850 - val_loss: 0.4195\n",
      "Epoch 255/600\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.4455 - val_loss: 0.4191\n",
      "Epoch 256/600\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.4530 - val_loss: 0.4187\n",
      "Epoch 257/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4627 - val_loss: 0.4178\n",
      "Epoch 258/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4553 - val_loss: 0.4176\n",
      "Epoch 259/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4445 - val_loss: 0.4170\n",
      "Epoch 260/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4718 - val_loss: 0.4167\n",
      "Epoch 261/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4213 - val_loss: 0.4153\n",
      "Epoch 262/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4677 - val_loss: 0.4152\n",
      "Epoch 263/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4696 - val_loss: 0.4150\n",
      "Epoch 264/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4890 - val_loss: 0.4157\n",
      "Epoch 265/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4523 - val_loss: 0.4154\n",
      "Epoch 266/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4400 - val_loss: 0.4161\n",
      "Epoch 267/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4504 - val_loss: 0.4163\n",
      "Epoch 268/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4762 - val_loss: 0.4157\n",
      "Epoch 269/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4639 - val_loss: 0.4153\n",
      "Epoch 270/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4415 - val_loss: 0.4147\n",
      "Epoch 271/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4252 - val_loss: 0.4144\n",
      "Epoch 272/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4805 - val_loss: 0.4140\n",
      "Epoch 273/600\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.4859 - val_loss: 0.4140\n",
      "Epoch 274/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.5118 - val_loss: 0.4140\n",
      "Epoch 275/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5114 - val_loss: 0.4147\n",
      "Epoch 276/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4857 - val_loss: 0.4150\n",
      "Epoch 277/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4721 - val_loss: 0.4141\n",
      "Epoch 278/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4551 - val_loss: 0.4141\n",
      "Epoch 279/600\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.4384 - val_loss: 0.4134\n",
      "Epoch 280/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4670 - val_loss: 0.4137\n",
      "Epoch 281/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4094 - val_loss: 0.4141\n",
      "Epoch 282/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4122 - val_loss: 0.4146\n",
      "Epoch 283/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5234 - val_loss: 0.4150\n",
      "Epoch 284/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4552 - val_loss: 0.4153\n",
      "Epoch 285/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4541 - val_loss: 0.4153\n",
      "Epoch 286/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4302 - val_loss: 0.4149\n",
      "Epoch 287/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4747 - val_loss: 0.4158\n",
      "Epoch 288/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4684 - val_loss: 0.4169\n",
      "Epoch 289/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4348 - val_loss: 0.4170\n",
      "Epoch 290/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4578 - val_loss: 0.4170\n",
      "Epoch 291/600\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4116 - val_loss: 0.4166\n",
      "Epoch 292/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4310 - val_loss: 0.4173\n",
      "Epoch 293/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4582 - val_loss: 0.4170\n",
      "Epoch 294/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4487 - val_loss: 0.4163\n",
      "Epoch 295/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4614 - val_loss: 0.4167\n",
      "Epoch 296/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4693 - val_loss: 0.4179\n",
      "Epoch 297/600\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4558 - val_loss: 0.4181\n",
      "Epoch 298/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4555 - val_loss: 0.4171\n",
      "Epoch 299/600\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5086 - val_loss: 0.4175\n",
      "Epoch 300/600\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4837 - val_loss: 0.4179\n",
      "Epoch 301/600\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.4334 - val_loss: 0.4170\n",
      "Epoch 302/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4365 - val_loss: 0.4164\n",
      "Epoch 303/600\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4617 - val_loss: 0.4164\n",
      "Epoch 304/600\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4662 - val_loss: 0.4167\n",
      "Epoch 00304: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b104b6040>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_mod.fit(x=X_train.values, \n",
    "          y=y_train.values, \n",
    "          epochs=600,\n",
    "          validation_data=(X_cv.values, y_cv.values), verbose=1,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6610ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss=pd.DataFrame(ann_mod.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967261f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanya/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = ann_mod.predict_classes(X_train.values)\n",
    "y_pred_cv = ann_mod.predict_classes(X_cv.values)\n",
    "precision_tr, recall_tr, fscore_tr, support_tr = precision_recall_fscore_support(\n",
    "    y_train.values, y_pred_tr, average='macro')\n",
    "precision_cv, recall_cv, fscore_cv, support_cv = precision_recall_fscore_support(\n",
    "    y_cv.values, y_pred_cv, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66573375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8318387233441604 0.7777112972565705 0.7905426018740467 None\n",
      "0.8557442557442557 0.7494745691467003 0.7717948717948717 None\n"
     ]
    }
   ],
   "source": [
    "print(precision_tr, recall_tr, fscore_tr, support_tr)\n",
    "print(precision_cv, recall_cv, fscore_cv, support_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "323829a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mod.save('ann_titanic.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc3a3e",
   "metadata": {},
   "source": [
    "## 3. Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f06ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[logReg_best,knn_best,decTree_best,rnFr_best,svm_best,adab_best,xgbst_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de47ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "SVC\n",
      "AdaBoostClassifier\n",
      "XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    print(str(model).split('(')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9ebbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:27:14] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "report_d={}\n",
    "for model in model_list:\n",
    "    name=str(model).split('(')[0]\n",
    "    filename = name + '_titanic.model'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    report=testModel(model, X_train, X_cv, y_train, y_cv)\n",
    "    report_d[name]=report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd832ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': array([0.7878336 , 0.77660329, 0.78104463, 0.80071235, 0.74842371,\n",
       "        0.76361222]),\n",
       " 'KNeighborsClassifier': array([0.81591525, 0.78415991, 0.79375232, 0.82717391, 0.7530475 ,\n",
       "        0.77192778]),\n",
       " 'DecisionTreeClassifier': array([0.98552395, 0.97914728, 0.98213562, 0.7380715 , 0.73420205,\n",
       "        0.73601695]),\n",
       " 'RandomForestClassifier': array([0.96730129, 0.95435004, 0.96002994, 0.80071235, 0.74842371,\n",
       "        0.76361222]),\n",
       " 'SVC': array([0.84174549, 0.77327926, 0.78740927, 0.86624869, 0.74555135,\n",
       "        0.76871853]),\n",
       " 'AdaBoostClassifier': array([0.81691265, 0.79914019, 0.80570042, 0.82088555, 0.76909065,\n",
       "        0.7850566 ]),\n",
       " 'XGBClassifier': array([0.96505445, 0.95612286, 0.96018728, 0.81486569, 0.78905703,\n",
       "        0.79904585])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b176b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
